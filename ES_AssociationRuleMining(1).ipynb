{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d31ed43-6060-4198-b4f1-bd69ae4b46a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n",
      "('spark.driver.extraJavaOptions', '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED')\n",
      "('spark.dynamicAllocation.minExecutors', '6')\n",
      "('spark.executor.memory', '10g')\n",
      "('spark.app.startTime', '1677710866414')\n",
      "('spark.executor.instances', '12')\n",
      "('spark.driver.cores', '5')\n",
      "('spark.executor.id', 'driver')\n",
      "('spark.dynamicAllocation.maxExecutors', '18')\n",
      "('spark.executor.cores', '2')\n",
      "('spark.driver.host', 'cs-235-11.argo.uwf.edu')\n",
      "('spark.driver.port', '43025')\n",
      "('spark.sql.shuffle.partitions', '12')\n",
      "('spark.app.submitTime', '1677710866205')\n",
      "('spark.master', 'local[20]')\n",
      "('spark.rdd.compress', 'True')\n",
      "('spark.driver.memory', '20g')\n",
      "('spark.app.name', 'AssociationRuleMining')\n",
      "('spark.executor.extraJavaOptions', '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED')\n",
      "('spark.serializer.objectStreamReset', '100')\n",
      "('spark.submit.pyFiles', '')\n",
      "('spark.submit.deployMode', 'client')\n",
      "('spark.dynamicAllocation.enabled', 'true')\n",
      "('spark.app.id', 'local-1677710867238')\n",
      "('spark.ui.showConsoleProgress', 'true')\n",
      "('spark.dynamicAllocation.shuffleTracking.enabled', 'true')\n"
     ]
    }
   ],
   "source": [
    "# spark imports \n",
    "import pyspark\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "import math\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "!pip install findspark\n",
    "\n",
    "import findspark\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "pd.__version__\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "    \n",
    "spark = ( \n",
    "    SparkSession\n",
    "    .builder\n",
    "    .master(\"local[20]\")\n",
    "    .appName(\"AssociationRuleMining\")\n",
    "    .config(\"spark.driver.cores\", '5')\n",
    "    .config(\"spark.driver.memory\", '20g')\n",
    "    .config(\"spark.executor.memory\", '10g')\n",
    "    .config(\"spark.executor.cores\", '2')\n",
    "    .config(\"spark.dynamicAllocation.shuffleTracking.enabled\", \"true\")\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\")\n",
    "    .config(\"spark.dynamicAllocation.minExecutors\", 6)\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\", 18)\n",
    "    .config(\"spark.executor.instances\", '12')\n",
    "    .config(\"spark.sql.shuffle.partitions\",'12')\n",
    "    .config(\"spark.submit.deployMode\", \"client\")\n",
    "    .getOrCreate()\n",
    "    )\n",
    "\n",
    "\n",
    "# Sanity check:  print spark configuration data.\n",
    "for a in spark.sparkContext._conf.getAll():\n",
    "    print(a)\n",
    "#File name to Binned Data\n",
    "path_to_data = '100BenignAndDiscoveryWithFullAttributes.csv'\n",
    "\n",
    "#reading data into pandas dataframe\n",
    "store_data = pd.read_csv(path_to_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a334c51-9d47-46e9-afac-ea834f3a7bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_tactic</th>\n",
       "      <th>dest_ip_zeek</th>\n",
       "      <th>src_ip_zeek</th>\n",
       "      <th>proto</th>\n",
       "      <th>conn_state</th>\n",
       "      <th>local_orig</th>\n",
       "      <th>local_resp</th>\n",
       "      <th>history</th>\n",
       "      <th>service</th>\n",
       "      <th>duration</th>\n",
       "      <th>orig_bytes</th>\n",
       "      <th>orig_pkts</th>\n",
       "      <th>orig_ip_bytes</th>\n",
       "      <th>resp_bytes</th>\n",
       "      <th>resp_pkts</th>\n",
       "      <th>resp_ip_bytes</th>\n",
       "      <th>missed_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_tactic  dest_ip_zeek  src_ip_zeek  proto  conn_state  local_orig  \\\n",
       "0             0             2            2      1           1           1   \n",
       "1             0             0            0      1           1           1   \n",
       "2             0             2            2      1           1           1   \n",
       "3             0             2            2      1           1           1   \n",
       "4             0             2            2      1           1           1   \n",
       "\n",
       "   local_resp  history  service  duration  orig_bytes  orig_pkts  \\\n",
       "0           1        1        3         0           0          2   \n",
       "1           1        1        3         0           0          2   \n",
       "2           1        1        3         0           0          2   \n",
       "3           1        1        3         0           0          2   \n",
       "4           1        1        3         0           0          2   \n",
       "\n",
       "   orig_ip_bytes  resp_bytes  resp_pkts  resp_ip_bytes  missed_bytes  \n",
       "0              2           0          2              2             1  \n",
       "1              3           0          2              2             1  \n",
       "2              2           0          2              2             1  \n",
       "3              2           0          2              2             1  \n",
       "4              3           0          2              2             1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88e95786-753f-41ba-b435-2d865ad1cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first step in ARM - Fiding all the possible unique values within the dataset to (later) find \n",
    "# all the unique unions that are possible to test against the chosen thresholds \n",
    "\n",
    "def findUniqueNum():     \n",
    "    #Contains all the unique values within the dataframe \n",
    "    numBin = []\n",
    "    \n",
    "    for i in range(len(transactions)):\n",
    "        for x in transactions[i]:\n",
    "            if (x not in numBin): \n",
    "                numBin.append(x)\n",
    "                \n",
    "    # Can test this on a smaller dataset for a better understanding          \n",
    "    #print(type(numBin)) \n",
    "    #print('The original Unique Numbers' + str(numBin))\n",
    "    \n",
    "    return numBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4710fc7e-5fe9-4658-a116-1f5b0a24545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method focuses on finding the first frequet unique individuals within dataset that passes support thresholds. \n",
    "# Only called once. \n",
    "# Will use this itemset to combine (later) into larger itemsets \n",
    "def firstFreqItemSet(numBin): \n",
    "    \n",
    "    associationRules = []  #this stays empty but is later used in Union()\n",
    "    newNumBin = [] # contains all unique individuals that had a high enough support value \n",
    "    ruleNum = 0 # to be used to call Union method\n",
    "\n",
    "    for i in numBin:\n",
    "        # and every transaction \n",
    "        for x in range(len(transactions)):  \n",
    "            # for every unique value found in a transaction \n",
    "            if(i in transactions[x]):    \n",
    "                #add a counter value \n",
    "                c[i]+=1\n",
    "    \n",
    "    for i in numBin:\n",
    "        if calculateSupport(c[i]) == True:\n",
    "            l[frozenset([i])]+=c[i]\n",
    "            newNumBin.append(i) \n",
    "            print(str(i))   # to be used for testing purposes on a smaller dataset \n",
    "            \n",
    "    union(newNumBin, l, associationRules, ruleNum)        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e936bbd8-2a2f-41ed-9c6f-a37535d28401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where num = the count of times that the itemset occurs \n",
    "# calculates support to decide if support is above the chosen threshold\n",
    "# returns true if it is above chosen threshold \n",
    "def calculateSupport(num):\n",
    "    support = num/len(transactions)\n",
    "    if (support >= sp):\n",
    "        return True \n",
    "    else:\n",
    "        return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b804cfb8-ae22-441c-b896-b86b4a137f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works to combine frequet itemsets \n",
    "# Tests against set thresholds \n",
    "\n",
    "def union(numBin, l, associationRules, ruleNum):\n",
    "    c = Counter() #resests C \n",
    "    nc = set() # holds sets \n",
    "    temp = list(l) # turns counter passed into method into a set \n",
    "    \n",
    "    #Unions all possible values within temp \n",
    "    #adds to nc \n",
    "    for i in range(0,len(temp)):\n",
    "        for j in range(i+1,len(temp)):\n",
    "            t = temp[i].union(temp[j])\n",
    "            nc.add(t)\n",
    "\n",
    "    nc = list(nc) #converts all possible unions to a list \n",
    "    cList = [] \n",
    "    \n",
    "    #for every possible union\n",
    "    for i in nc:\n",
    "        y = list(i)        \n",
    "        #if confidence is deemed high enough \n",
    "        if(calculateConfidence(y) == True):\n",
    "            c[i] = 0\n",
    "            #and you can find it in a transaction \n",
    "            for q in range(len(transactions)):\n",
    "                \n",
    "                # turn the union into a set again and check for subset of set of one transaction\n",
    "                t = transactions[q]\n",
    "          \n",
    "                temp = set(t)           \n",
    "                tempT =set(i)\n",
    "            \n",
    "                if(tempT.issubset(temp)):\n",
    "                        # then increment the counter \n",
    "                        c[i]+=1\n",
    "\n",
    "    l = Counter()\n",
    "    \n",
    "    #For every set with high enough confidence values, check the support \n",
    "    for i in c:\n",
    "        if calculateSupport(c[i]) == True:\n",
    "            l[i]+=c[i]\n",
    "            \n",
    "    #Create rule         \n",
    "    for i in l:\n",
    "    \n",
    "        support = (l[i]/len(transactions))\n",
    "        #print('This is the support 1  ' + str(support))\n",
    "        #print(str(i))\n",
    "        confidence = returnConfidence(i)\n",
    "        lift = returnLift(i, confidence)\n",
    "        ruleNum = ruleNum + 1\n",
    "        rule = ('Rule: ' + str(ruleNum) + ' ' + str(list(i)) + '[ support =' + str(support) + '  confidence = ' + str(confidence) + ' lift = ' + str(lift) + ' ]' + '\\n') \n",
    "        \n",
    "        # Seeing if Rule is already within the list of rules, just a double check  \n",
    "        associationRules = repeatIdentifier(rule, associationRules)  \n",
    "    \n",
    "    #If no more unions pass the thresholds end program\n",
    "    if(len(l) == 0):\n",
    "        printResults(associationRules) \n",
    "    #else continue on with the rest of the unions \n",
    "    else:       \n",
    "        #print('size of list of acceptable unions' + str(len(numBin))) // Testing purposes\n",
    "        union( numBin, l, associationRules, ruleNum) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c759ea40-8a46-42b2-9af8-dff7d02609e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finds if rule is already contained in list. Adds it to list if the rule is not found and then returns the list\n",
    "#Works to prevent repeat association rules \n",
    "def repeatIdentifier(rule, ruleList): \n",
    "    if ((rule in ruleList) == True):\n",
    "        print('Rule already in List')\n",
    "    else:\n",
    "        ruleList.append(rule)\n",
    "\n",
    "    return ruleList\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d517df73-21d7-48c3-a131-c5484b5ac013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates confidence \n",
    "def calculateConfidence(num):\n",
    "    numList = list(num)\n",
    "    numCountAntecedent = []\n",
    "    \n",
    "    #Contains all the unique values within the dataframe \n",
    "    numBin = []\n",
    "    numCountA = 0\n",
    "    numCountP = 0\n",
    "    \n",
    "    for x in range(len(transactions)): \n",
    "        x = list(transactions[x]) \n",
    "        if (x.count(num[0]) > 0):\n",
    "            numCountA = numCountA + 1        \n",
    "    \n",
    "    #The whole transaction\n",
    "    for x in range(len(transactions)):\n",
    "        setX = set(transactions[x])\n",
    "        num = set(num) \n",
    "        if(num.issubset(setX)):\n",
    "            numCountP = numCountP + 1\n",
    "    confidence = numCountP/numCountA\n",
    "    if (confidence >= conf):\n",
    "        if (returnLift(num, confidence) >=liftE):\n",
    "            return True \n",
    "        else:\n",
    "            return False\n",
    "    else: \n",
    "        return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5cd0f25-15ba-41eb-9571-de044097a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns the Confidence of an Association Rule \n",
    "#Confidence=transactions containing A and B / transactions containing A \n",
    "\n",
    "def returnConfidence(num): \n",
    "    \n",
    "    numList = list(num)\n",
    "    numCountAntecedent = []\n",
    "    numBin = []\n",
    "    numCountA = 0\n",
    "    numCountP = 0\n",
    "    \n",
    "    # Number of transactions that the antecedent is available \n",
    "    for x in range(len(transactions)): \n",
    "        x = list(transactions[x]) \n",
    "        if (x.count(numList[0]) > 0):\n",
    "            numCountA = numCountA + 1        \n",
    "    \n",
    "    #Number of transactions that the consequent and the antecedent is available \n",
    "    for x in range(len(transactions)):\n",
    "        setX = set(transactions[x])\n",
    "        num = set(num) \n",
    "        if(num.issubset(setX)):\n",
    "            numCountP = numCountP + 1    \n",
    "    confidence = numCountP/numCountA\n",
    "    return confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fa06d14-f2a8-4154-920f-2b5a9e1bc105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method Calculates the Lift value and returns it \n",
    "# Lift = Confidence of if A then B / support of B\n",
    "\n",
    "def returnLift(transaction, confidence):\n",
    "    \n",
    "    numList = list(transaction)\n",
    "    \n",
    "    numCountAntecedent = []\n",
    "    numBin = []\n",
    "    newWord =''\n",
    "    numCountA = 0\n",
    "    numCountP = 0\n",
    "    \n",
    "    #Number of occurences of the antecendet \n",
    "    for x in range(len(transactions)): \n",
    "        x = list(transactions[x]) \n",
    "        if (x.count(numList[0]) > 0):\n",
    "            numCountA = numCountA + 1   \n",
    "            \n",
    "    numList.remove(numList[0])\n",
    "    \n",
    "    #Number of occurences of the consequent \n",
    "    for x in range(len(transactions)):\n",
    "        setX = set(transactions[x])\n",
    "        num = set(numList) \n",
    "        if(num.issubset(setX)):\n",
    "            numCountP = numCountP + 1\n",
    "            \n",
    "    supportP = numCountP/len(transactions)\n",
    "    \n",
    "    lift = confidence/supportP\n",
    "    \n",
    "    return lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0205ae22-1bf1-4a33-8820-a23826e89118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prints association rules to file \n",
    "def printResults(associationRules):     \n",
    "    file = open('Test#.txt', 'w')\n",
    "    file.writelines(associationRules)   \n",
    "    print('End of program')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a1f645b-b87e-4069-b2d4-e095817c966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Altering Binned Data information to produce a new list with header in each data point \n",
    "transactions = store_data.values.tolist()\n",
    "\n",
    "columnNames = []\n",
    "newList = [] \n",
    "bigList = []\n",
    "\n",
    "# iterating the columns\n",
    "for col in store_data.columns:\n",
    "    columnNames.append(col) \n",
    "    \n",
    "for i in range(len(transactions)):\n",
    "    z = -1\n",
    "    newList = [] \n",
    "\n",
    "    for x in transactions[i]:\n",
    "        T = str(x)\n",
    "        z = z + 1\n",
    "        d = str(columnNames[z]) + '=' + T\n",
    "        newList.append(d) \n",
    "    bigList.append(newList)\n",
    "transactions = bigList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae0b6386-75cf-481e-a006-2892ec87f6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the findUniqueNum() method, about to traverse the dataframe\n",
      "src_ip_zeek=2\n",
      "local_orig=1\n",
      "local_resp=1\n",
      "missed_bytes=1\n",
      "End of program\n"
     ]
    }
   ],
   "source": [
    "transactionsWHeader = []\n",
    "indicator = 0\n",
    "\n",
    "\n",
    "#indicating ARM Thresholds \n",
    "liftE = 0 #lift\n",
    "sp = 0.99 #Support\n",
    "conf =0.99 #Confidence\n",
    "\n",
    "a = Counter()\n",
    "b = []\n",
    "\n",
    "\n",
    "#Create global counter variables \n",
    "c = Counter()\n",
    "l = Counter()\n",
    "l2 = Counter()\n",
    "\n",
    "emptyList = []\n",
    "supportValues = [] \n",
    "num = findUniqueNum()\n",
    "firstFreqItemSet(num) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a472ace3-d8e2-42f0-b27c-d87e85d66456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1595e6a7-010a-41d6-8ab1-b11151c563f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
